{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from src.engine import train_one_epoch, evaluate\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCODataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, annotation, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.coco = COCO(annotation)\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        coco = self.coco\n",
    "        img_id = self.ids[index]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        coco_annotation = coco.loadAnns(ann_ids)\n",
    "        path = coco.loadImgs(img_id)[0]['file_name']\n",
    "        img = Image.open(os.path.join(self.root, path))\n",
    "\n",
    "        num_objs = len(coco_annotation)\n",
    "\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            xmin = coco_annotation[i]['bbox'][0]\n",
    "            ymin = coco_annotation[i]['bbox'][1]\n",
    "            xmax = xmin + coco_annotation[i]['bbox'][2]\n",
    "            ymax = ymin + coco_annotation[i]['bbox'][3]\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        \n",
    "        class_labels = [annotation['category_id'] for annotation in coco_annotation]\n",
    "        labels = torch.tensor(class_labels, dtype=torch.int64)\n",
    "\n",
    "        img_id = torch.tensor([img_id])\n",
    "        areas = []\n",
    "        for i in range(num_objs):\n",
    "            areas.append(coco_annotation[i]['area'])\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        my_annotation = {}\n",
    "        my_annotation[\"boxes\"] = boxes\n",
    "        my_annotation[\"labels\"] = labels\n",
    "        my_annotation[\"image_id\"] = img_id\n",
    "        my_annotation[\"area\"] = areas\n",
    "        my_annotation[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, my_annotation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "def get_transform():\n",
    "    transforms = []\n",
    "    transforms.append(torchvision.transforms.ToTensor())\n",
    "    return torchvision.transforms.Compose(transforms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=20.22s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.67s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_data_dir = '../data/coco2017/train2017/'\n",
    "train_coco = '../data/coco2017/annotations/instances_train2017.json'\n",
    "\n",
    "train_batch_size = 2\n",
    "\n",
    "my_dataset = COCODataset(root=train_data_dir,\n",
    "                          annotation=train_coco,\n",
    "                          transforms=get_transform()\n",
    "                          )\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(my_dataset,\n",
    "                                          batch_size=train_batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0,\n",
    "                                          collate_fn=collate_fn,\n",
    "                                          pin_memory=False)\n",
    "\n",
    "test_data_dir = '../data/coco2017/val2017/'\n",
    "test_coco = '../data/coco2017/annotations/instances_val2017.json'\n",
    "\n",
    "test_coco = COCODataset(root=test_data_dir,\n",
    "                          annotation=test_coco,\n",
    "                          transforms=get_transform()\n",
    "                          )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_coco,\n",
    "                                          batch_size=2,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=0,\n",
    "                                          collate_fn=collate_fn,\n",
    "                                          pin_memory=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 80\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "# checkpoint = torch.load('model/New_fasterRcnn_pidsix.pth')  # 가중치 파일의 경로를 지정하세요\n",
    "# in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "# model.load_state_dict(checkpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 13\u001b[0m     train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n\u001b[0;32m     14\u001b[0m     lr_scheduler\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     16\u001b[0m     model_save_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel/FasterRCNN_COCO2017\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m.pth\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\root\\Desktop\\Vision model\\examples\\src\\engine.py:29\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler)\u001b[0m\n\u001b[0;32m     24\u001b[0m     lr_scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mLinearLR(\n\u001b[0;32m     25\u001b[0m         optimizer, start_factor\u001b[39m=\u001b[39mwarmup_factor, total_iters\u001b[39m=\u001b[39mwarmup_iters\n\u001b[0;32m     26\u001b[0m     )\n\u001b[0;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m images, targets \u001b[39min\u001b[39;00m metric_logger\u001b[39m.\u001b[39mlog_every(data_loader, print_freq, header):\n\u001b[1;32m---> 29\u001b[0m     images \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(image\u001b[39m.\u001b[39;49mto(device) \u001b[39mfor\u001b[39;49;00m image \u001b[39min\u001b[39;49;00m images)\n\u001b[0;32m     30\u001b[0m     targets \u001b[39m=\u001b[39m [{k: v\u001b[39m.\u001b[39mto(device) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m t\u001b[39m.\u001b[39mitems()} \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m targets]\n\u001b[0;32m     31\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast(enabled\u001b[39m=\u001b[39mscaler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\root\\Desktop\\Vision model\\examples\\src\\engine.py:29\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     24\u001b[0m     lr_scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mLinearLR(\n\u001b[0;32m     25\u001b[0m         optimizer, start_factor\u001b[39m=\u001b[39mwarmup_factor, total_iters\u001b[39m=\u001b[39mwarmup_iters\n\u001b[0;32m     26\u001b[0m     )\n\u001b[0;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m images, targets \u001b[39min\u001b[39;00m metric_logger\u001b[39m.\u001b[39mlog_every(data_loader, print_freq, header):\n\u001b[1;32m---> 29\u001b[0m     images \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(image\u001b[39m.\u001b[39;49mto(device) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m images)\n\u001b[0;32m     30\u001b[0m     targets \u001b[39m=\u001b[39m [{k: v\u001b[39m.\u001b[39mto(device) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m t\u001b[39m.\u001b[39mitems()} \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m targets]\n\u001b[0;32m     31\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast(enabled\u001b[39m=\u001b[39mscaler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD( params, lr=0.0005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.01)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=1000)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    model_save_path = f'model/FasterRCNN_COCO2017{epoch}.pth'\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "model_save_path = 'model/New_fasterRcnn_pidsix.pth'\n",
    "\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "print(\"That's it!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Model Load\n",
      "------Prediction Start------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 5492/5492 [23:39<00:00,  3.87it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "num_classes = 14\n",
    "\n",
    "print('Test Model Load')\n",
    "test_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "in_features = test_model.roi_heads.box_predictor.cls_score.in_features\n",
    "test_model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "test_model.load_state_dict(torch.load('model/New_fasterRcnn_pidsix.pth'))\n",
    "test_model.to(device)\n",
    "test_model.eval()\n",
    "\n",
    "print('------Prediction Start------')\n",
    "all_predictions = []\n",
    "for images, targets in tqdm(test_loader, desc='test',leave=True):\n",
    "    images = [image.to(device) for image in images]\n",
    "    with torch.no_grad():\n",
    "        predictions = test_model(images)\n",
    "    all_predictions.extend(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Convert predictions and targets to COCO format------\n",
      "loading annotations into memory...\n",
      "Done (t=0.22s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "------Evaluate Start------\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=6.61s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.80s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.088\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.082\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.091\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.091\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "mAP_bbox: 0.0744672915436928\n"
     ]
    }
   ],
   "source": [
    "coco_results = []\n",
    "\n",
    "print('------Convert predictions and targets to COCO format------')\n",
    "for prediction, target in zip(all_predictions, test_loader.dataset.coco.dataset['annotations']):\n",
    "    for box, label, score in zip(prediction['boxes'], prediction['labels'], prediction['scores']):\n",
    "        coco_result = {\n",
    "            'image_id': target['image_id'],\n",
    "            'category_id': label.item(),\n",
    "            'bbox': box.cpu().numpy().tolist(),\n",
    "            'score': score.item()\n",
    "        }\n",
    "        coco_results.append(coco_result)\n",
    "\n",
    "coco_gt = COCO('json/My_test.json')\n",
    "coco_dt = coco_gt.loadRes(coco_results)\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "\n",
    "print('------Evaluate Start------')\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()\n",
    "\n",
    "mAP_bbox = coco_eval.stats[0]\n",
    "print(\"mAP_bbox:\", mAP_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Prediction Start------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 5492/5492 [23:50<00:00,  3.84it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def convert_predictions_to_coco_format(predictions, image_ids):\n",
    "    coco_results = []\n",
    "    for prediction, image_id in zip(predictions, image_ids):\n",
    "        for box, label, score in zip(prediction['boxes'], prediction['labels'], prediction['scores']):\n",
    "            coco_result = {\n",
    "                'image_id': image_id.item(),\n",
    "                'category_id': label.item(),\n",
    "                'bbox': box.cpu().numpy().tolist(),\n",
    "                'score': score.item()\n",
    "            }\n",
    "            coco_results.append(coco_result)\n",
    "    return coco_results\n",
    "\n",
    "all_predictions = []\n",
    "image_ids = []\n",
    "\n",
    "print('------Prediction Start------')\n",
    "for images, targets in tqdm(test_loader, desc='test', leave=True):\n",
    "    images = [image.to(device) for image in images]\n",
    "    image_ids.extend(targets[0]['image_id'].cpu().numpy())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = test_model(images)\n",
    "    all_predictions.extend(predictions)\n",
    "\n",
    "# 예측 결과를 COCO 형식으로 변환\n",
    "coco_results = convert_predictions_to_coco_format(all_predictions, image_ids)\n",
    "\n",
    "# JSON 파일로 저장\n",
    "output_json_path = 'predictions.json'\n",
    "with open(output_json_path, 'w') as output_file:\n",
    "    json.dump(coco_results, output_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과를 COCO 형식으로 변환\n",
    "coco_results = convert_predictions_to_coco_format(all_predictions, image_ids)\n",
    "\n",
    "# JSON 파일로 저장\n",
    "output_json_path = 'predictions.json'\n",
    "with open(output_json_path, 'w') as output_file:\n",
    "    json.dump(coco_results, output_file, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron_rev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
